{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mission 3 pandasを使ったデータ操作\n",
    "\n",
    "> データ分析業務の8割はデータクレンジングと言われるほど重要かつ、頻繁に行う作業です。\n",
    "> pandasを用いてデータ操作を行い、より分析や可視化を行いやすいデータに整理していく方法を学んでいきましょう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-1. 新しい列、行の追加\n",
    "\n",
    "pandasを用いて新しいデータの追加や既存データの削除,修正を行います。\n",
    "まず、保育園のデータをインデックスを指定せず読み込み、データの大きさを`.shape`を用いて確認します。\n",
    "```\n",
    "In [1]: import pandas as pd\n",
    "        hoikuen = pd.read_csv('hoikuen.csv',encoding='shift_jis')\n",
    "        hoikuen.shape\n",
    "\n",
    "Out[1]: (58, 10)\n",
    "```\n",
    "データの`「列」`の追加の仕方と`「行」`の追加の仕方を説明します。\n",
    "\n",
    "【データの`「列」`の追加の仕方】\n",
    "新しい列にデータを追加したい場合は、`DataFrame['列名']`で値を代入できます。\n",
    "値の代入の仕方は大きく下記の3種類あります。\n",
    "```\n",
    "1. スカラーの追加\n",
    "2. リストの追加\n",
    "3. Seriesの追加\n",
    "```\n",
    "3種類の代入方法の棲み分けは以下となっていますのでどんなデータを代入するかによって使い分けましょう。\n",
    "```\n",
    "どの行にも共通した値を代入する際には、`スカラーの追加`  \n",
    "行ごとに値が異なる値を代入する際には、`リストの追加 `   \n",
    "他の列データから値を加工して代入する際には、`Seriesの追加`    \n",
    "```\n",
    "保育園のデータに新しく`所属都道府県`という列名で、代入する値は`東京都`という文字列を代入してみましょう。\n",
    "この場合はどの行にも共通した値を代入するので、`スカラーの追加`を行います。\n",
    "```\n",
    "In [2]: hoikuen['所属都道府県'] = '東京都'\n",
    "        hoikuen['所属都道府県']\n",
    "\n",
    "Out[2]: 0     東京都\n",
    "        1     東京都\n",
    "        2     東京都\n",
    "        ・・・\n",
    "        55    東京都\n",
    "        56    東京都\n",
    "        57    東京都\n",
    "        Name: 所属都道府県, dtype: object\n",
    "```\n",
    "保育園のデータに新しく`保育園ID`という列名、値は`['001','002','003',...,'057','058']`というリストを代入してみましょう。\n",
    "行ごとに値が異なる値を代入するので、`リストの追加`を行います。\n",
    "要素数と行数が一致していない場合はエラー(`ValueError`)となるので、桁数とリストの大きさが一致しているかを注意してください。\n",
    "```\n",
    "In [3]: hoikuen['保育園ID'] = ['001','002','003',...,'057','058']\n",
    "        hoikuen['保育園ID']\n",
    "\n",
    "Out[3]: 0     001\n",
    "        1     002\n",
    "        2     003\n",
    "        ・・・\n",
    "        55    056\n",
    "        56    057\n",
    "        57    058\n",
    "        Name: 保育園ID, dtype: object\n",
    "```\n",
    "保育園のデータに新しく`0-1歳児定員`という列名、値は列`0歳児定員`と列`1歳児定員`列の要素の足し算を行った値を代入してみましょう。\n",
    "他の列データから値を加工して代入するので、`Seriesの追加`を行います。\n",
    "```\n",
    "In [4]: hoikuen['0-1歳児定員'] = hoikuen['0歳児定員'] + hoikuen['1歳児定員']\n",
    "        hoikuen['0-1歳児定員']\n",
    "\n",
    "Out[4]: 0     12.0\n",
    "        1     32.0\n",
    "        2     14.0\n",
    "        ・・・\n",
    "        55    20.0\n",
    "        56    15.0\n",
    "        57    18.0\n",
    "        Name: 0-1歳児定員, dtype: float64\n",
    "```\n",
    "一見すると足し算を正しく行えていそうですが、一部データ不備により演算を正しく行えていない箇所が存在します。\n",
    "保育園のデータで、施設名が`グローバルキッズ新大塚園`のデータを抽出し、見てみましょう。\n",
    "```\n",
    "In [5]: hoikuen[hoikuen['施設名']== 'グローバルキッズ新大塚園'][['0歳児定員','1歳児定員','0-1歳児定員']]\n",
    "\n",
    "Out[5]:    0歳児定員    1歳児定員    0-1歳児定員\n",
    "        41  NaN            10.0           NaN\n",
    "```\n",
    "上記出力を見ると列`0歳児定員`が欠損値（NaN）を含んでいるため、pandasでのデータ処理に漏れが起こっていそうです。\n",
    "データを加工する際は、意図した処理がされているか、抜け漏れがないかの確認をしながら進めて行きましょう。\n",
    "今回のような欠損値に対しての抜け漏れを回避するために事前に欠損値を含んでいるデータを洗い出し、値を分析し補完を行います。\n",
    "詳細は後述の`欠損値の確認を行う`というオペレーションにて説明します。\n",
    "\n",
    "`DataFrame['列名']= ○○ `の追加方法以外にも、`assign`で列の追加を行うことも可能です。\n",
    "`所属都道府県`という列名で、値は`東京都`という文字列を`assign`を用いて代入してみましょう。\n",
    "```\n",
    "In [6]: hoikuen = hoikuen.assign(所属都道府県='東京')\n",
    "        hoikuen['所属都道府県']\n",
    "\n",
    "Out[6]: 0     東京都\n",
    "        1     東京都\n",
    "        2     東京都\n",
    "        ・・・\n",
    "        55    東京都\n",
    "        56    東京都\n",
    "        57    東京都\n",
    "        Name: 所属都道府県, dtype: object\n",
    "```\n",
    "【データの`「行」`の追加の仕方】\n",
    "新規で行を追加したい場合は、`loc`で行を選択して値を代入することができます。\n",
    "値の代入の仕方については、列の代入と同様に3種の方法があリます。\n",
    "行追加を行った場合は末尾にデータ追加となるので、データ確認の際には`tail`を用いて末尾を確認しましょう。\n",
    "\n",
    "では、保育園のデータに新しくインデックスが58で、代入する値は一律`100`という数値を代入してみましょう。\n",
    "新規追加する前のデータの最終行のインデックスが57であるため、新規追加時はインデックス58を指定しています。\n",
    "この場合はどの行にも共通した値を代入するので、`スカラーの追加`を行います。\n",
    "```\n",
    "In [7]: hoikuen.loc[58] = 100\n",
    "        hoikuen.tail(1)\n",
    "\n",
    "Out[7]:     No.  施設名 公私区分 認可区分  合計園児定員  0歳児定員  1歳児定員  2歳児定員  3歳児定員  4・5歳児定員\n",
    "        58  100  100   100     100      100         100.0     100.0    100.0     100.0    100.0\n",
    "```\n",
    "保育園のデータに新しく`テスト保育園`という行で、値は`[59, 'テスト保育園', 'test', 'test', 100, 20, 20, 20, 20, 20]`を代入してみましょう。\n",
    "列ごとに値が異なる値を代入するので、`リストの追加`を行います。\n",
    "要素数と列数が一致していない場合はエラー(`ValueError`)となるので、列数とリストの大きさが一致しているかを注意してください。\n",
    "```\n",
    "In [8]: hoikuen.loc[59] = [59, 'テスト保育園', 'test', 'test', 100, 20, 20, 20, 20, 20]\n",
    "        hoikuen.tail(1)\n",
    "\n",
    "Out[8]:      No. 施設名      公私区分  認可区分  合計園児定員  0歳児定員  1歳児定員  2歳児定員  3歳児定員  4・5歳児定員\n",
    "        59   59  テスト保育園  test    test     100         20.0      20.0      20.0     20.0      20.0\n",
    "```\n",
    "保育園のデータに新しく藍染保育園と久堅保育園の行の要素の足し算を行った値を代入してみましょう。\n",
    "他の行データから値を加工して代入するので、`Seriesの追加`を行います。\n",
    "```\n",
    "In [9]: hoikuen.loc[60] = hoikuen.loc[0] + hoikuen.loc[1]\n",
    "        hoikuen.tail(1)\n",
    "\n",
    "Out[9]:      No. 施設名             公私区分            認可区分              合計園児定員  0歳児定員  1歳児定員  2歳児定員  3歳児定員  4・5歳児定員\n",
    "        60    3  藍染保育園久堅保育園  区立保育園区立保育園  認可保育園認可保育園    210         12.0      32.0      37.0     43.0      86.0 \n",
    "```\n",
    "***\n",
    "### 課題\n",
    "\n",
    "1. SIGNATE保育園を保育園データの末尾に追加し、df1に読み込んでください。\n",
    "追加前のデータの最終行のNo.は58となっており、SIGNATE保育園の詳細なデータは以下となります。\n",
    "\n",
    "【SIGNATE保育園詳細データ】\n",
    "  - `No.`59\n",
    "  - `施設名`SIGNATE保育園\n",
    "  - `公私区分`区立保育園\n",
    "  - `認可区分`認可保育園\n",
    "  - `合計園児定員`100\n",
    "  - `0歳児定員`20.0\n",
    "  - `1歳児定員`20.0\n",
    "  - `2歳児定員`20.0\n",
    "  - `3歳児定員`20.0\n",
    "  - `4・5歳児定員`20.0\n",
    "\n",
    "2. 保育園のデータにおいて新しい列所属区を追加し、値は文京区の文字列を追加し、df2に読み込んでください。\n",
    "ただし、SIGNATE保育園は追加済みの状態とします。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandasのインポート\n",
    "import pandas as pd\n",
    "hoikuen = pd.read_csv('hoikuen.csv',encoding='shift_jis')\n",
    "\n",
    "# Q1\n",
    "hoikuen.loc[58] = [59, 'SIGNATE保育園', '区立保育園', '認可保育園', 100, 20.0, 20.0, 20.0, 20.0, 20.0]\n",
    "df1 = hoikuen\n",
    "df1.tail()\n",
    "\n",
    "# Q2\n",
    "hoikuen['所属区'] = '文京区'  # (or) hoikuen.assign(所属区='文京区')\n",
    "df2 =  hoikuen\n",
    "df2['所属区']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-2. 既存の列、行の削除とデータの修正\n",
    "\n",
    "pandasを用いて既存のデータの列や行の削除、並びにデータの修正を行います。<br>\n",
    "まず、保育園のデータをインデックスを指定せず読み込み、データを大きさを`.shape()`を用いて確認します。\n",
    "```\n",
    "In [1]: import pandas as pd\n",
    "        hoikuen = pd.read_csv('hoikuen.csv',encoding=\"shift_jis\")\n",
    "        hoikuen.shape\n",
    "\n",
    "Out[1]: (58, 10)\n",
    "```\n",
    "DataFrameの列を削除するには、通常次の3つのいずれかを使用します。<br>\n",
    "今回はこのうち代表的である、`drop()`を用いて列の削除を行います。　\n",
    "\n",
    "- pandas.DataFrame.drop()\n",
    "- pandas.DataFrame.pop()\n",
    "- del文\n",
    "\n",
    "`drop()`を用いて列の削除を行う際には、引数`columns`に削除したい列名を指定し列を削除します。<br>\n",
    "複数の列を削除する場合は、列名のリストを引数`columns`に渡してください。<br>\n",
    "保育園のデータの列`No.`を削除します。\n",
    "```\n",
    "In [2]: hoikuen.drop(columns='No.').head(1)\n",
    "\n",
    "Out[2]:       施設名  公私区分  　認可区分  　合計園児定員　 0歳児定員　 1歳児定員　2歳児定員 3歳児定員 4・5歳児定員\n",
    "        0  藍染保育園  区立保育園  認可保育園  87           0.0       12.0     　15.0   20.0     40.0   \n",
    "```\n",
    "```\n",
    "In [3]: hoikuen.drop(columns='No.')\n",
    "        hoikuen.head(1)\n",
    "\n",
    "Out[3]:    No.    施設名  　　公私区分  　認可区分  　合計園児定員　 0歳児定員　 1歳児定員　2歳児定員 3歳児定員 4・5歳児定員\n",
    "        0    1    藍染保育園  区立保育園  認可保育園  87           0.0        12.0     15.0    20.0     40.0 \n",
    "```\n",
    "`In [2]`と`In [3]`の出力結果を比較するとわかるように、`drop()`を用いて列の削除を行った時点では、元のDataFrameには反映されていません。<br>\n",
    "また注意点として下記のような処理を試しに行ってみましょう。\n",
    "```\n",
    "In [4]: hoikuen = hoikuen.drop(columns='No.')\n",
    "        hoikuen.head(1)\n",
    "\n",
    "Out[4]:    施設名  　　公私区分  　認可区分  　合計園児定員　 0歳児定員　1歳児定員　2歳児定員  3歳児定員 4・5歳児定員\n",
    "        0  藍染保育園  区立保育園  認可保育園  87           0.0      12.0      15.0    20.0    40.0 \n",
    "```\n",
    "`In [4]`は保育園のデータの列`No.`を削除したDataFrameを、元の`hoikuen`のDataFrameに代入しています。<br>\n",
    "一見良さそうに見えますが、削除した列を元に戻したい場合はどうでしょうか。<br>\n",
    "削除した列のデータを持つDataFrameが存在しないので、データの読み込みを一から行う必要があります。<br>\n",
    "上記の事態を避けるためにも元のDataFrameをcopy()を用いて列削除を行う用のDataFrameを用意し、データの削除を行いましょう。<br>\n",
    "下記プログラムだと、削除した列No.のデータが必要になった場合でも、hoikuen_copyから取得することが可能となります。\n",
    "```\n",
    "In [5]: hoikuen_copy = hoikuen.copy()  \n",
    "        hoikuen = hoikuen.drop(columns='No.')\n",
    "        hoikuen.head(1)\n",
    "\n",
    "Out[5]:    施設名  　　公私区分  　認可区分  　合計園児定員　 0歳児定員　 1歳児定員 2歳児定員 3歳児定員 4・5歳児定員\n",
    "        0  藍染保育園  区立保育園  認可保育園  87           0.0       12.0      15.0    20.0     40.0 \n",
    "```\n",
    "`drop()`に削除対象行のインデックスと引数`axis=0`を指定します。<br>\n",
    "`drop()`を用いての処理は元のDataFrameには反映されていないことにも注意しましょう。<br>\n",
    "保育園のデータの1行目のデータを削除し、変更したDataFrameをhoikuen_copyに代入します。<br>\n",
    "```\n",
    "In [6]: hoikuen_copy = hoikuen.drop(0, axis=0)\n",
    "        hoikuen_copy.head(1)\n",
    "\n",
    "Out[6]:    No.  施設名     公私区分  　認可区分  　合計園児定員　 0歳児定員　 1歳児定員　2歳児定員 3歳児定員 4・5歳児定員\n",
    "        1  2    久堅保育園  区立保育園  認可保育園  123          12.0      20.0     22.0     23.0     46.0\n",
    "```\n",
    "行を削除する際には`drop()`を用いることもできますが、削除したい行列を含まないデータを条件で絞り込みを行うことも多くあります。<br>\n",
    "保育園のデータの1行目のデータを削除する場合も、施設名に`藍染保育園`を含まないデータを抽出し、hoikuen_copyに代入することで同義となります。\n",
    "```\n",
    "In [7]: hoikuen_copy = hoikuen[hoikuen['施設名']!='藍染保育園']\n",
    "        hoikuen_copy.head(1)\n",
    "\n",
    "Out[7]:    No.  施設名     公私区分  　認可区分  　合計園児定員　 0歳児定員　 1歳児定員　2歳児定員 3歳児定員 4・5歳児定員\n",
    "        1  2    久堅保育園  区立保育園  認可保育園  123          12.0      20.0      22.0    23.0     46.0\n",
    "```\n",
    "DataFrameオブジェクトの列の名前を変更する際には、`rename`関数の引数`columns`に辞書オブジェクトを指定します。<br>\n",
    "辞書のキーと値には、それぞれ変更前と変更後の列名を与えます。<br>\n",
    "通常、この操作は元のDataFrameオブジェクトを変更しないことに注意してください。<br>\n",
    "<br>\n",
    "保育園のデータの公私区分の列名を保育園区分に変更し、変更したDataFrameをhoikuen_copyに代入します。\n",
    "```\n",
    "In [8]: hoikuen_copy = hoikuen.rename(columns={'公私区分': '保育園区分'})\n",
    "        hoikuen_copy.head(1)\n",
    "\n",
    "Out[8]:    No.  施設名     保育園区分  認可区分  　合計園児定員　 0歳児定員　 1歳児定員　2歳児定員 3歳児定員 4・5歳児定員\n",
    "        0    1  藍染保育園  区立保育園  認可保育園  87           0.0       12.0     15.0     20.0     40.0\n",
    "```\n",
    "***\n",
    "### 課 題\n",
    "\n",
    "1. 保育園データの列名の園児の定員に関するデータを削除し、hoikuen_copy1に読み込んでください。\n",
    "\n",
    "1. 保育園のデータの久堅保育園のデータを削除し、hoikuen_copy2に読み込んでください。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandasのインポート\n",
    "import pandas as pd\n",
    "hoikuen = pd.read_csv('hoikuen.csv',encoding='shift_jis')\n",
    "\n",
    "# Q1\n",
    "hoikuen_copy1 = hoikuen.copy()\n",
    "hoikuen_copy1 = hoikuen_copy1.drop(columns=['合計園児定員','0歳児定員','1歳児定員','2歳児定員','3歳児定員','4・5歳児定員'])\n",
    "hoikuen_copy1.head()\n",
    "\n",
    "# Q2\n",
    "hoikuen_copy2 = hoikuen[hoikuen['施設名']!='久堅保育園']\n",
    "hoikuen_copy2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（１）の別解法例 ： hoikuen_copy1 = hoikuen[[col for col in hoikuen.columns if '定員' not in col]]\n",
    "\n",
    "（２）の別解法例 ： hoikuen_copy2 = hoikuen[hoikuen['施設名'] !='久堅保育園']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-3. データのクレンジング\n",
    "\n",
    "データ分析の際には、データの量と質が重要となります。<br>\n",
    "データを増やすことは実現が厳しい場合がありますが、データの質を分析者側で上げることは可能です。<br>\n",
    "そのデータの質を上げることを`データクレンジング`や`データ整備`、`データ前処理`、`データ洗浄`などと言います。<br>\n",
    "データ分析はデータクレンジングが8割、データ分析業の最初の一歩言われていますので、丁寧に学習していきましょう。\n",
    "\n",
    "まずはデータの欠損の確認を行います。<br>\n",
    "なぜ欠損を確認しないといけないのかの代表的な理由は以下となります。\n",
    "\n",
    "1. 統計的処理が不可能になる\n",
    "2. データ資源が無駄になる\n",
    "3. 予測モデル作成時に欠損値が不都合になる\n",
    "\n",
    "データの欠損確認は`isnull`を用いて、DataFrameの要素で値が欠損していれば`True`、欠損していなければ`False`を返します。<br>\n",
    "保育園のデータを読み込んで、欠損の確認を行います。\n",
    "```\n",
    "In [1]: import pandas as pd\n",
    "        hoikuen = pd.read_csv('hoikuen.csv',encoding=\"shift_jis\")\n",
    "        hoikuen.isnull().head(1)\n",
    "\n",
    "Out[1]:    No.    施設名   公私区分   認可区分  合計園児定員  0歳児定員  1歳児定員  2歳児定員  3歳児定員  4・5歳児定員\n",
    "        0  False  False  False      False    False       False     False    False     False     False\n",
    "```\n",
    "合計値を取得することができる`sum()`と組み合わせることで欠損している要素数を列ごとに確認することができます。\n",
    "```\n",
    "In [2]: hoikuen.isnull().sum()\n",
    "\n",
    "Out[2]: No.            0\n",
    "        施設名          0\n",
    "        公私区分        0\n",
    "        認可区分        0\n",
    "        合計園児定員     0\n",
    "        0歳児定員       6\n",
    "        1歳児定員       1\n",
    "        2歳児定員       1\n",
    "        3歳児定員       6\n",
    "        4・5歳児定員     13\n",
    "        dtype: int64\n",
    "```\n",
    "また、データの要約を表示する`info`でも欠損値の有無を確認できます。<br>\n",
    "`info`ではDataFrameの行数、列数、各列の列名、各列に格納されるデータの型、メモリ使用量が表示されます。\n",
    "```\n",
    "In [3]: hoikuen.info()\n",
    "\n",
    "Out[3]: <class 'pandas.core.frame.DataFrame'>\n",
    "        Int64Index: 61 entries, 0 to 60\n",
    "        Data columns (total 10 columns):\n",
    "        No.        61 non-null int64\n",
    "        施設名        61 non-null object\n",
    "        公私区分       61 non-null object\n",
    "        認可区分       61 non-null object\n",
    "        合計園児定員     61 non-null int64\n",
    "        0歳児定員      55 non-null float64\n",
    "        1歳児定員      60 non-null float64\n",
    "        2歳児定員      60 non-null float64\n",
    "        3歳児定員      55 non-null float64\n",
    "        4・5歳児定員    48 non-null float64\n",
    "        dtypes: float64(5), int64(2), object(3)\n",
    "        memory usage: 7.7+ KB\n",
    "```\n",
    "これらの出力結果から保育園のデータでは`0歳児定員`、`1歳児定員`、`2歳児定員`、`3歳児定員`、`4・5歳児定員`の欠損値をもつ列だとわかりました。<br>\n",
    "欠損値を持つデータに対してのデータ操作は大きく2つのアプローチがあります。<br>\n",
    "どちらの方法にもメリット、デメリットがありますので分析を行う状況に合わせてアプローチ方法を決めましょう。\n",
    "```\n",
    "1. 欠損値を持つデータを削除する（リストワイズ削除）\n",
    "    - メリット：欠損値を持つ不明瞭なデータを削除することで、データの品質は高くなる。\n",
    "    - デメリット：データ数が少なくなる。時系列のデータには用いることができない。\n",
    "\n",
    "2. 欠損値補完を行う\n",
    "    - メリット：データ数が少なくならない。補完する値によって、予測モデルの精度が上がる。\n",
    "    - デメリット：補完する値によって元のデータとの乖離が発生し、予測モデルの精度が下がる。\n",
    "```\n",
    "上記記載の1のように、欠損値を持つレコードを削除する場合は`dropna`を用います。<br>\n",
    "`dropna`は、データの要素に欠損値を持つレコードを削除します。<br>\n",
    "保育園のデータを読み込み、欠損値を持つレコードを削除をすることで残りのレコード数がいくつかになるのかを確認しましょう。\n",
    "```\n",
    "\n",
    "In [4]: hoikuen.dropna().shape\n",
    "\n",
    "Out[4]: (41, 10)\n",
    "```\n",
    "元の保育園データの大きさは`(58, 10)`であるため、レコード数が`17件`少なくなっています。<br>\n",
    "欠損値を持つレコードを削除する場合は全データの30%近いデータを削除することが確認できました。<br>\n",
    "別のアプローチとして、欠損値補完のアプローチをとってみましょう。\n",
    "\n",
    "保育園のデータで欠損値が一つでも含まれる行・列を抽出し、欠損の仕方を確認しましょう。<br>\n",
    "流れを分解し、まず保育園のデータから欠損値が含まれているかを`isnull`を使った確認します。\n",
    "```\n",
    "\n",
    "In [5]: hoikuen.isnull()\n",
    "\n",
    "Out[5]:   No.    施設名   公私区分   認可区分  合計園児定員  0歳児定員  1歳児定員  2歳児定員  3歳児定員  4・5歳児定員\n",
    "        False   False    False    False       False     False     False    False     False    False\n",
    "        False   False    False    False       False     False     False    False     False    False\n",
    "        False   False    False    False       False     False     False    False     False    False\n",
    "        ...\n",
    "        False   False    False    False       False     False     False    False     True     False\n",
    "        False   False    False    False       False     False     False    False     False    False\n",
    "        False   False    False    False       False     False     False    False     False    True\n",
    "```\n",
    "次に、行または列に一つでも`True`が含まれていると`True`を返す`any`を用います。<br>\n",
    "欠損値を持つ列が一つでもあるレコードを抽出したいので、`axis=1`とします。<br>\n",
    "`axis`処理を図解した画像も記載しますが、列に沿った処理は`axis=0`、行に沿った処理`axis=1`と覚えましょう。\n",
    "\n",
    "![axis](axis.png)\n",
    "```\n",
    "\n",
    "In [6]: hoikuen.isnull().any(axis=1)\n",
    "\n",
    "Out[6]:     0     False\n",
    "            1     False\n",
    "            2     False\n",
    "            ...\n",
    "            55     True\n",
    "            56    False\n",
    "            57     True\n",
    "            dtype: bool\n",
    "```\n",
    "先ほど説明した`isnull`と`any`を組み合わせて、欠損値を持っているレコードの抽出条件とします。<br>\n",
    "保育園のデータの中で欠損値を持っているレコードの先頭3行を確認します。\n",
    "```\n",
    "\n",
    "In [7]: hoikuen[hoikuen.isnull().any(axis=1)].head(3)\n",
    "\n",
    "Out[7]:     No.  施設名          ... 合計園児定員　 0歳児定員　 1歳児定員　 2歳児定員　 3歳児定員　 4・5歳児定員\n",
    "        19    20    春日臨時保育所             62           9.0      20.0       18.0       15.0       NaN\n",
    "        22    23    たんぽぽ保育園分園         19           6.0       6.0        7.0        NaN       NaN\n",
    "        23    24    たんぽぽ保育園第二分園     20           NaN       6.0        7.0        7.0       NaN\n",
    "```\n",
    "具体的に欠損値を持つデータを見ると、<br>\n",
    "`合計園児定員 = 0歳児定員 + 1歳児定員 + 2歳児定員 + 3歳児定員 + 4・5歳児定員`が成立しそうだと分析できます。\n",
    "よって、保育園のデータの園児定員関連の列の欠損は0で埋めるべきだと判断することができます。<br>\n",
    "このように欠損値を何で埋めるべきなのかをデータをみながら判断していきましょう。\n",
    "また、代表的な欠損値の補完の仕方は以下のようなものが存在します。\n",
    "様々な手法やアルゴリズムが存在しますので興味がある場合は深掘りしてみましょう。\n",
    "```\n",
    "1. 欠損値を対象列の平均値や中央値、最頻値で補完する\n",
    "2. 欠損値を対象列で取り得ない値（−999や999など）で補完する\n",
    "3. 欠損値をレコード前後の値から算出し、補完する（※時系列データなど）\n",
    "4. 欠損値を推論する予測モデルを作成し、推論値で補完する\n",
    "```\n",
    "欠損値補完を行う際には`fillna`を用います。\n",
    "`fillna`は引数に与えた数値や文字列でDataFrameの欠損値を補完します。\n",
    "保育園のデータの欠損値を全て0で補完しましょう。\n",
    "```\n",
    "\n",
    "In [8]: hoikuen = hoikuen.fillna(0)\n",
    "        hoikuen.head(3)\n",
    "\n",
    "Out[8]:     No.  施設名   ... 合計園児定員 0歳児定員 1歳児定員 2歳児定員 3歳児定員 4・5歳児定員\n",
    "        0    1  藍染保育園        87          0.0      12.0      15.0      20.0     40.0\n",
    "        1    2  久堅保育園       123         12.0      20.0      22.0      23.0     46.0\n",
    "        2    3  青柳保育園        85          0.0      14.0      18.0      18.0     35.0\n",
    "```\n",
    "また、欠損値補完が終わった時点の各列のデータ型を再確認しましょう。\n",
    "データ型は`dtypes`で確認することができます。\n",
    "```\n",
    "\n",
    "In [9]: hoikuen.dtypes\n",
    "\n",
    "Out[9]: No.               int64\n",
    "        施設名             object\n",
    "        公私区分           object\n",
    "        認可区分           object\n",
    "        合計園児定員　　    int64\n",
    "        0歳児定員　　      float64\n",
    "        1歳児定員　　      float64\n",
    "        2歳児定員　　      float64\n",
    "        3歳児定員　　　　　 float64\n",
    "        4・5歳児定員       float64\n",
    "        dtype: object\n",
    "```\n",
    "列`0歳児定員`や列`1歳児定員`のデータ型が小数点を持つ`float64`となっていますが、定員数を意味するため列`合計園児定員`と同様の`int64`が適切であると考えられます。<br>\n",
    "データ型の変更は`astype`を用い、引数に型変換予定の辞書を指定します。<br>\n",
    "保育園のデータにて園児関連の列のデータ型を変更し、`info`を使って適切なデータ型に変換できているかを確認しましょう。\n",
    "```\n",
    "\n",
    "In [10]: hoikuen = hoikuen.fillna(0)\n",
    "         hoikuen = hoikuen.astype({'0歳児定員': int ,\n",
    "                                    '1歳児定員': int ,\n",
    "                                    '2歳児定員': int ,\n",
    "                                    '3歳児定員': int ,\n",
    "                                    '4・5歳児定員': int })\n",
    "\n",
    "         hoikuen.info()\n",
    "\n",
    "Out[10]: <class 'pandas.core.frame.DataFrame'>\n",
    "        RangeIndex: 58 entries, 0 to 57\n",
    "        Data columns (total 10 columns):\n",
    "        No.        58 non-null int64\n",
    "        施設名        58 non-null object\n",
    "        公私区分       58 non-null object\n",
    "        認可区分       58 non-null object\n",
    "        合計園児定員     58 non-null int64\n",
    "        0歳児定員      58 non-null int64\n",
    "        1歳児定員      58 non-null int64\n",
    "        2歳児定員      58 non-null int64\n",
    "        3歳児定員      58 non-null int64\n",
    "        4・5歳児定員    58 non-null int64\n",
    "        dtypes: int64(7), object(3)\n",
    "        memory usage: 4.7+ KB\n",
    "```\n",
    "***\n",
    "### 課 題\n",
    "\n",
    "- 実際にhoikuen.csvを読み込み、プログラムでデータを確認した上で、次の内、保育園のデータ説明について誤っているものを全て選択してください。\n",
    "\n",
    "  - [ ] ４・５歳児定員に欠損値を持っている保育園は12つ存在する\n",
    "  - [ ] 各列の欠損値を各列データで各々の平均値で補完する場合は、hoikuen.fillna(hoikuen.mean())となる\n",
    "  - [ ] 各レコードでもっとも欠損値の要素が多いものは、欠損値を３つ持っている\n",
    "  - [ ] 欠損値を補完しなくても、dtypeによるデータ型の変更は可能である\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandasのインポート\n",
    "import pandas as pd\n",
    "hoikuen = pd.read_csv('hoikuen.csv',encoding='shift_jis')\n",
    "\n",
    "\n",
    "hoikuen.isnull().sum(axis=1)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-4. データの結合\n",
    "\n",
    "データ分析では、1つのSeriesまたはDataFrameオブジェクトだけではなく、複数のオブジェクトを組み合わせてデータを確認することがあります。<br>\n",
    "代表的な結合方法は以下の3種類ありますが、今回は頻出である`concat`関数を用いた結合と`merge`関数を用いた結合について説明します。\n",
    "```\n",
    "1. merge関数を用いた結合\n",
    "2. concat関数を用いた結合\n",
    "3. join関数を用いた結合\n",
    "```\n",
    "\n",
    "【merge関数を用いた結合】\n",
    "まず結合する前のデータを読み込みます。<br>\n",
    "今回は結合の仕方がわかりやすいように、レコード数を最小限にしています。\n",
    "```\n",
    "\n",
    "In [1]: import pandas as pd\n",
    "        df1 = pd.DataFrame({'保育園ID': ['001','002','003'],\n",
    "                            '全収容人数': [100, 200, 300],\n",
    "                            '保育園区分':['区立保育園','区立保育園','私立保育園']})\n",
    "\n",
    "        df2 = pd.DataFrame({'保育園ID': ['001','002','003'],\n",
    "                            '保育士人数': [10, 20, 30]})\n",
    "\n",
    "        df3 = pd.DataFrame({'保育園区分': ['国立保育園','私立保育園'],\n",
    "                            '保育士最低必要人数': [10, 20]})\n",
    "```\n",
    "2つのDataFrameの結合は`pd.merge`で行います。\n",
    "結合方法のキーとなる列の指定には引数`on`、結合の方法は引数`how`を指定します。\n",
    "引数`on`にはキーとなる列名、引数`how`は下記の指定方法が存在します。\n",
    "キーとなる列名が複数となる場合は、結合したい列名のリストを引数として渡してください。\n",
    "```\n",
    "inner: 内部結合。両方のデータに含まれるキーだけを残す。\n",
    "left: 左外部結合。１つ目のデータのキーをすべて残す。\n",
    "right: 右外部結合。2つ目のデータのキーをすべて残す。\n",
    "outer: 完全外部結合。すべてのキーを残す。\n",
    "```\n",
    "先ほど読み込んだデータ`df1`と`df2`を、`保育園ID`をキーとして内部結合をします。\n",
    "保育士人数がうまく結合できていることが確認できます。\n",
    "```\n",
    "\n",
    "In [2]: pd.merge(df1, df2, on='保育園ID', how='inner')\n",
    "\n",
    "Out[2]:     保育園ID  全収容人数  保育園区分 保育士人数\n",
    "        0   001      100       区立保育園  10\n",
    "        1   002      200       区立保育園  20\n",
    "        2   003      300       私立保育園  30\n",
    "```\n",
    "同じ方法で、先ほど読み込んだデータ`df1`と`df3`を、`保育園区分`をキーとして内部結合をします。\n",
    "```\n",
    "\n",
    "In [3]: pd.merge(df1, df3, on='保育園区分', how='inner')\n",
    "\n",
    "Out[3]:     保育園ID  全収容人数  保育園区分  保育士最低必要人数\n",
    "        0   003      300        私立保育園  20\n",
    "```\n",
    "`In [3]`では、`df3`が区立保育園の保育士最低必要人数のデータを持っていないので、結合の際に区立保育園のデータが抜け落ちています。<br>\n",
    "この場合、データ`df1`と`df3`を結合する際には左外部結合`how='left'`とするのが正しいです。<br>\n",
    "区立保育園の保育士最低必要人数に関してはデータとしては持ち合わせていないので、欠損値NaNと表示されます。\n",
    "```\n",
    "In [4]: pd.merge(df1, df3, on='保育園区分', how='left')\n",
    "\n",
    "Out[4]:     保育園ID  全収容人数  保育園区分  保育士最低必要人数\n",
    "        0   001      100        区立保育園  NaN\n",
    "        1   002      200        区立保育園  NaN\n",
    "        2   003      300        私立保育園  20.0\n",
    "```\n",
    "【concat関数を用いた結合】\n",
    "まず結合する前のデータを読み込みます。\n",
    "同様に結合の仕方がわかりやすいように、レコード数を最小限にしています。\n",
    "```\n",
    "In [5]: import pandas as pd\n",
    "        df1 = pd.DataFrame({'保育園ID': ['001','002','003'],\n",
    "                     '全収容人数': [100, 200, 300],\n",
    "                     '保育園区分':['区立保育園','区立保育園','私立保育園']})\n",
    "\n",
    "        df2 = pd.DataFrame({'保育園ID': ['004','005','006'],\n",
    "                             '全収容人数': [400, 500, 600],\n",
    "                             '保育園区分':['区立保育園','区立保育園','私立保育園']})\n",
    "\n",
    "        df3 = pd.DataFrame({'保育園ID': ['007','008','009'],\n",
    "                             '全収容人数': [700, 800, 900],\n",
    "                             '保育園区分':['区立保育園','区立保育園','私立保育園']})\n",
    "```\n",
    "先ほど読み込んだデータ`df1`と`df2`を縦方法に連結をします。\n",
    "```\n",
    "In [6]: pd.concat([df1,df2])\n",
    "\n",
    "Out[6]:     保育園ID  全収容人数  保育園区分\n",
    "        0   001      100        区立保育園\n",
    "        1   002      200        区立保育園\n",
    "        2   003      300        私立保育園\n",
    "        0   004      400        区立保育園\n",
    "        1   005      500        区立保育園\n",
    "        2   006      600        私立保育園\n",
    "```\n",
    "2種類以上のデータを結合することも可能です。\n",
    "```\n",
    "In [7]: pd.concat([df1,df2,df3])\n",
    "\n",
    "Out[7]:     保育園ID  全収容人数  保育園区分\n",
    "        0   001      100        区立保育園\n",
    "        1   002      200        区立保育園\n",
    "        2   003      300        私立保育園\n",
    "        0   004      400        区立保育園\n",
    "        1   005      500        区立保育園\n",
    "        2   006      600        私立保育園\n",
    "        0   007      700        区立保育園\n",
    "        1   008      800        区立保育園\n",
    "        2   009      900        私立保育園\n",
    "```\n",
    "引数`axis`を指定することで、縦方法の結合なのか、横方向の結合なのかの連結方法を指定することも可能です。<br>\n",
    "先ほど読み込んだデータ`df1`と`df2`を横方向に結合します。\n",
    "```\n",
    "In [8]: pd.concat([df1,df2],axis=1)\n",
    "\n",
    "Out[8]:     保育園ID  全収容人数  保育園区分 保育園ID  全収容人数  保育園区分\n",
    "        0   001      100       区立保育園  004     400        区立保育園\n",
    "        1   002      200       区立保育園  005     500        区立保育園\n",
    "        2   003      300       私立保育園  006     600        私立保育園\n",
    "```\n",
    "***\n",
    "### 課 題\n",
    "\n",
    "- 次の内、保育園のデータと保育園データ詳細の説明について誤っているものを1つ選択してください。\n",
    "保育園データと保育園のデータ詳細については、別タブに詳細も記載しているので、合わせてご確認ください。\n",
    "\n",
    "  - [ ] 土日祝日対応可の保育園は19施設ある\n",
    "  - [ ] 藍染保育園では児童1人あたり、0.25人以上の保育士が担当する（※小数点第3位を切り捨て）\n",
    "  - [ ] モニカ茗荷谷は補助が無い\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandasのインポート\n",
    "import pandas as pd\n",
    "hoikuen = pd.read_csv('hoikuen.csv',encoding='shift_jis')\n",
    "hoikuen_detail = pd.read_csv('hoikuen_dummy_detail.csv',encoding='shift_jis')\n",
    "\n",
    "df_all = pd.merge(hoikuen,hoikuen_detail)\n",
    "\n",
    "c = 0\n",
    "for i in range(58):\n",
    "    if df_all['土日祝日対応可否'][i] == '可':\n",
    "        c += 1\n",
    "    \n",
    "print(c)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
